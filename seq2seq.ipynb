{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "[None, None, None, 1]\n",
      "[None, None, None, 32]\n",
      "[None, None, None, 32]\n",
      "[None, None, None, 64]\n",
      "[None, None, None, 128]\n",
      "[None, None, None, 256]\n",
      "[None, None, None, 512]\n",
      "WARNING:tensorflow:From <ipython-input-1-4d7d8bac7bf3>:214 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "iteration: 0; train loss: 2.3224966526031494\n",
      "iteration: 100; train loss: 2.3111324310302734\n",
      "iteration: 200; train loss: 2.3150434494018555\n",
      "iteration: 300; train loss: 2.2851853370666504\n",
      "iteration: 400; train loss: 1.9569895267486572\n",
      "iteration: 500; train loss: 0.7836259603500366\n",
      "iteration: 600; train loss: 0.34083080291748047\n",
      "iteration: 700; train loss: 0.42251288890838623\n",
      "iteration: 800; train loss: 0.5400060415267944\n",
      "iteration: 900; train loss: 2.070481777191162\n",
      "iteration: 1000; train loss: 0.16651111841201782\n",
      "validation accuracy: 0.9449996948242188\n",
      "iteration: 1100; train loss: 0.1616920828819275\n",
      "iteration: 1200; train loss: 0.32266414165496826\n",
      "iteration: 1300; train loss: 0.06564852595329285\n",
      "iteration: 1400; train loss: 0.19933202862739563\n",
      "iteration: 1500; train loss: 0.020691201090812683\n",
      "iteration: 1600; train loss: 0.08530440926551819\n",
      "iteration: 1700; train loss: 0.053426891565322876\n",
      "iteration: 1800; train loss: 0.1254107654094696\n",
      "iteration: 1900; train loss: 0.1253587007522583\n",
      "iteration: 2000; train loss: 0.014085834845900536\n",
      "validation accuracy: 0.9733997583389282\n",
      "[[  1.03946491e-06   3.99713736e-06   3.74342344e-05 ...,   9.14938937e-06\n",
      "    5.27406082e-05   1.00438054e-04]\n",
      " [  9.99495983e-01   2.22074068e-05   6.60210717e-05 ...,   2.06782397e-06\n",
      "    3.24107168e-05   8.09357425e-06]\n",
      " [  2.52326863e-05   2.52834521e-04   5.19109562e-05 ...,   5.44554205e-05\n",
      "    7.78926187e-06   3.61445826e-04]\n",
      " ..., \n",
      " [  8.27951415e-04   1.73540115e-01   8.08573782e-01 ...,   4.98455949e-04\n",
      "    8.47695977e-04   2.37529189e-03]\n",
      " [  2.35384359e-04   9.98261273e-01   8.50692159e-05 ...,   1.44807433e-04\n",
      "    4.05411818e-04   6.09326926e-05]\n",
      " [  5.36584703e-05   2.81008100e-03   9.90678847e-01 ...,   4.30385611e-04\n",
      "    9.31769260e-04   7.06757477e-04]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Simple wrapper to fetch MNIST dataset and concat images to obtain sequences of numbers.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "width, height = 28, 28\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def get_mnist():\n",
    "    train_labels, train_data = mnist.train.labels, mnist.train.images\n",
    "    val_labels, val_data = mnist.validation.labels, mnist.validation.images\n",
    "\n",
    "    train_data = np.reshape(train_data, (-1, 28, 28))\n",
    "    train_labels = np.reshape(train_labels, (-1, 5, 10))\n",
    "    val_data = np.reshape(val_data, (-1, 28, 28))\n",
    "    val_labels = np.reshape(val_labels, (-1, 5, 10))\n",
    "\n",
    "    train_data = np.transpose(train_data, (1, 0, 2))\n",
    "    train_data = np.reshape(train_data, (28, -1, 28 * 5))\n",
    "    train_data = np.transpose(train_data, (1, 0, 2))\n",
    "    train_data = np.expand_dims(train_data, 3)\n",
    "\n",
    "    val_data = np.transpose(val_data, (1, 0, 2))\n",
    "    val_data = np.reshape(val_data, (28, -1, 28 * 5))\n",
    "    val_data = np.transpose(val_data, (1, 0, 2))\n",
    "    val_data = np.expand_dims(val_data, 3)\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels\n",
    "\n",
    "\n",
    "'''\n",
    "    im2latex WIP, Jan Ivanecky\n",
    "    MIT license\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    \n",
    "# load dataset, for now MNIST\n",
    "train_data, train_labels, val_data, val_labels = get_mnist()\n",
    "\n",
    "# functions for fetching variables\n",
    "def get_weight_matrix(name, shape):\n",
    "    return tf.get_variable(name, shape, dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def get_weight_matrix_conv2d(name, shape):\n",
    "    return tf.get_variable(name, shape, dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "def get_bias_vector(name, shape):\n",
    "    return tf.get_variable(name, shape, dtype=tf.float32, initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "# wrapper for convolution + relu\n",
    "def convolutional_layer(name, channels, input):\n",
    "    print(input.get_shape().as_list())\n",
    "    input_channels = input.get_shape().as_list()[3]\n",
    "    conv_filter = get_weight_matrix_conv2d(name + '_w', [3,3,input_channels,channels])\n",
    "    conv_bias = get_bias_vector(name + '_b', [channels])\n",
    "    conv = tf.nn.conv2d(input, conv_filter, [1,1,1,1], 'SAME')\n",
    "    relu = tf.nn.relu(conv + conv_bias)\n",
    "    return relu\n",
    "\n",
    "# max pooling wrapper\n",
    "def max_pooling(input):\n",
    "    max = tf.nn.max_pool(input, [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    return max\n",
    "\n",
    "# I'm using MLP in multiple places so this comes in handy\n",
    "def MLP(input, size, depth, output_size):\n",
    "    x = input\n",
    "    for i in range(depth):\n",
    "        i_size = x.get_shape().as_list()[1] if i == 0 else size\n",
    "        o_size = output_size if i == depth - 1 else size\n",
    "        W = get_weight_matrix('W' + str(i), [i_size,o_size])\n",
    "        b = get_bias_vector('b' + str(i), o_size)\n",
    "        o = tf.matmul(x,W) + b\n",
    "        x = tf.nn.relu(o) if i < depth - 1 else o\n",
    "    return x\n",
    "\n",
    "def ConvNet(input):\n",
    "\n",
    "    '''\n",
    "        Processes input image, outputs 'annotations'\n",
    "        Note that it's fully convolutional so it takes image of any size as an input\n",
    "    '''\n",
    "    #print(input)\n",
    "    relu1 = convolutional_layer('conv1', 32, input)\n",
    "    relu1_2 = convolutional_layer('conv1_2', 32, relu1)\n",
    "    max1 = max_pooling(relu1_2)\n",
    "    relu2 = convolutional_layer('conv2', 64, max1)\n",
    "    max2 = max_pooling(relu2)\n",
    "    relu3 = convolutional_layer('conv3', 128, max2)\n",
    "    relu4 = convolutional_layer('conv4', 256 , relu3)\n",
    "    max4 = max_pooling(relu4)\n",
    "    relu5 = convolutional_layer('conv5', 512 , max4)\n",
    "    relu6 = convolutional_layer('conv6', 512 , relu5)\n",
    "    max5 = max_pooling(relu6)\n",
    "    dims = tf.shape(max5)\n",
    "    width, height, channels = dims[2], dims[1], max5.get_shape().as_list()[3]\n",
    "    output = tf.reshape(max5, [-1, height * width, channels])\n",
    "    return output\n",
    "\n",
    "def annotation_weights(annotations, state, scope):\n",
    "\n",
    "    '''\n",
    "        Computes weights for all annotations conditioned on the current state of LSTM\n",
    "    '''\n",
    "\n",
    "    annotation_count, feature_count = tf.shape(annotations)[1], annotations.get_shape().as_list()[2]\n",
    "    state_size = state.get_shape().as_list()[1]\n",
    "    c = annotations\n",
    "    c = tf.reshape(c, [-1,feature_count])\n",
    "    h = tf.expand_dims(state, 1)\n",
    "    h = tf.tile(h, [1,annotation_count,1])\n",
    "    h = tf.reshape(h, [-1, state_size])\n",
    "    with tf.variable_scope(scope or 'attention') as scope_:\n",
    "        y3 = MLP(tf.concat(1,[h,c]), state_size, 3, 1)\n",
    "    y3 = tf.reshape(y3, [-1, annotation_count])\n",
    "    e = tf.nn.softmax(y3)\n",
    "    e = tf.expand_dims(e, 2)\n",
    "    return e\n",
    "\n",
    "class LSTM_Attention(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    '''\n",
    "        Implements LSTM cell with attention mechanism and deep output layer, it's basically just\n",
    "        a wrapper for an LSTM cell.\n",
    "        \n",
    "        Note that input to the LSTM ('input' argument to the __call__ method) is not used at all, \n",
    "        because when attention mechanism is used, input for each time step is just a weighted sum\n",
    "        of annotation vectors, where only the weights differ between time steps. I store \n",
    "        annotation vectors in the __init__ and compute weights when necessary.\n",
    "        Other important thing to mention is that LSTM step is conditioned on the previous output, which\n",
    "        means I need to store it with the LSTM state to be able to use this cell in combination with dynamic_rnn.\n",
    "        I pack the output with the new state when returning the new state and unpack it at the begginning of the __call__. \n",
    "    '''\n",
    "\n",
    "    def __init__(self, size, keep_rate, annotations, output_size):\n",
    "        self.hidden_size = size\n",
    "        self.out_size = output_size\n",
    "        self.lstm = tf.nn.rnn_cell.LSTMCell(size, state_is_tuple=True)\n",
    "        self.lstm = tf.nn.rnn_cell.DropoutWrapper(self.lstm, output_keep_prob=keep_rate)\n",
    "        self.annotations = annotations\n",
    "        #lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * depth, state_is_tuple=True)\n",
    "        \n",
    "    def init_state(self):\n",
    "        mean_annotation = tf.reduce_mean(self.annotations, 1)\n",
    "        with tf.variable_scope('init_c') as scope_c:\n",
    "            init_c = MLP(mean_annotation, 128, 2, self.hidden_size)\n",
    "        with tf.variable_scope('init_h') as scope_h:\n",
    "            init_h = MLP(mean_annotation, 128, 2, self.hidden_size)\n",
    "        return [tf.nn.rnn_cell.LSTMStateTuple(init_c, init_h), tf.zeros([tf.shape(self.annotations)[0], self.out_size])]\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.hidden_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.out_size\n",
    "\n",
    "    def __call__(self, input, state, scope=None, prev_output=None):\n",
    "        state, prev_output = state\n",
    "        with tf.variable_scope(scope or type(self).__name__):  \n",
    "            # compute current context\n",
    "            with tf.variable_scope('attention') as scope:\n",
    "                aw = annotation_weights(self.annotations, state[1], scope)\n",
    "            current_context = tf.reduce_sum(aw * self.annotations, 1)\n",
    "            \n",
    "            # new state, conditioned on previous output, previous state and context\n",
    "            input = tf.concat(1, [current_context, prev_output])\n",
    "            with tf.variable_scope('decoder') as scope:\n",
    "                output, state = self.lstm(input,state)\n",
    "\n",
    "            # compute output of the deep output layer\n",
    "            deep_output_input = tf.concat(1,[output, current_context, prev_output]) # output layer input is an LSTM input + current context + previous output\n",
    "            with tf.variable_scope('output') as scope:\n",
    "                deep_output = MLP(deep_output_input, 256, 1, self.out_size)\n",
    "            output = tf.nn.softmax(deep_output)\n",
    "        return output, [state, output] # packing state and output together to be able to use dynamic_rnn\n",
    "\n",
    "# build the whole system, note that input image size can be arbitrary (should be constant within a batch ofc.)\n",
    "#def build_model(vocabulary_size):\n",
    "vocabulary_size = train_labels.shape[2] # 10\n",
    "inputs = tf.placeholder(tf.float32, [None, None, None, 1])\n",
    "labels = tf.placeholder(tf.float32, [None, None, vocabulary_size])\n",
    "labels_ = tf.reshape(labels, [-1, vocabulary_size])\n",
    "keep_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "# get annotation vectors\n",
    "conv_output = ConvNet(inputs)\n",
    "\n",
    "# compute prediction\n",
    "lstm = LSTM_Attention(512, keep_rate, conv_output, vocabulary_size)\n",
    "outputs, _ = tf.nn.dynamic_rnn(lstm, tf.zeros_like(labels), initial_state = lstm.init_state()) \n",
    "outputs = tf.reshape(outputs, [-1, vocabulary_size])\n",
    "\n",
    "# accuracy and loss computation\n",
    "correct_predictions = tf.equal(tf.cast(tf.argmax(outputs, 1), tf.int32), tf.cast(tf.argmax(labels_, 1), tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(tf.log(outputs) * labels_,reduction_indices=[1]))\n",
    "\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "#prediction = tf.argmax(outputs, 1)\n",
    "#    return inputs, labels, train, accuracy, loss, keep_rate, outputs\n",
    "\n",
    "#inputs, labels, train, accuracy, loss, keep_rate, outputs = build_model(train_labels.shape[2])\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "p = 0\n",
    "BATCH_SIZE = 10\n",
    "EVAL_INTERVAL = 1000\n",
    "MAX_ITER = 2000\n",
    "\n",
    "for i in range(MAX_ITER + 1):\n",
    "    nums = train_data[p: p + BATCH_SIZE]\n",
    "    label = train_labels[p: p + BATCH_SIZE]\n",
    "    p += BATCH_SIZE\n",
    "    if p >= len(train_labels):\n",
    "        p = 0\n",
    "\n",
    "    feed_dict = {inputs: nums, labels: label, keep_rate: 0.5}\n",
    "    l, _ = sess.run([loss, train], feed_dict)\n",
    "    if i % 100 == 0:\n",
    "        print('iteration: {}; train loss: {}'.format(i, l))\n",
    "        \n",
    "    if i % EVAL_INTERVAL == 0 and i > 0:\n",
    "        feed_dict = {inputs: val_data, keep_rate: 1.0, labels: val_labels}\n",
    "        acc = sess.run(accuracy, feed_dict)\n",
    "        print('validation accuracy: {}'.format(acc))\n",
    "\n",
    "\n",
    "result = outputs.eval(feed_dict={inputs: val_data, keep_rate: 1.0, labels: val_labels}, session=sess)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result[0]))\n",
    "print(np.argmax(result[1]))\n",
    "print(np.argmax(result[2]))\n",
    "print(np.argmax(result[3]))\n",
    "print(np.argmax(result[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels[0][0])\n",
    "print(val_labels[0][1])\n",
    "print(val_labels[0][2])\n",
    "print(val_labels[0][3])\n",
    "print(val_labels[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
